{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                        Ground Truth of DBLP Data Set\n",
    "![title](pics/gt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file is com-dblp.ungraph.txt in which One row indicates the nodes id that falls in same community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/com-dblp.all.cmty.txt\", \"r\")\n",
    "file2 = open(\"data/communityalldblp.txt\", \"w\")\n",
    "\n",
    "i=0\n",
    "for items in file:\n",
    "    y = items.split(\"\\t\")\n",
    "    for item in y:\n",
    "        file2.write(\"%d\\t\"%int(item))\n",
    "        file2.write(\"%d\\n\"%i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth of snap was in the form of all nodes in one communities were listed in one row so we convert it into \n",
    "edge list form where each node is listed with its respective community in one row tab separated.\n",
    "The above shown ground truth communities are formatted in edge-list form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting DBLP Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "\n",
    "file2 = open(\"data/LovaindblpCommunities.txt\", \"r\")\n",
    "file3 = open(\"data/SortedDBLPCommunities.txt\", \"w\")\n",
    "\n",
    "i=0\n",
    "nodesArr = []\n",
    "commArr = []\n",
    "combined = []\n",
    "\n",
    "for items in file2:\n",
    "\titems = items.strip()\n",
    "\titems = items.split(\"\\t\")\n",
    "\tnodes = items[0].strip()\n",
    "\tnodesArr.append(nodes) \n",
    "\tcommunity1 = items[1].strip()\n",
    "\tcommArr.append(community1)\n",
    "\n",
    "List_length = len(nodesArr)\n",
    "\t\n",
    "for i in range(List_length):\n",
    "\tcombined.append([nodesArr[i], commArr[i]])\n",
    "\t#file3.write(nodesArr[i] + \"\\t\" + commArr[i] + \"\\n\")\n",
    "\n",
    "#combined = sorted(combined, key=lambda x: x[0].lower())\n",
    "combined = sorted(combined, key=lambda x: int(x[0]))\n",
    "\n",
    "#print (combined[0])\n",
    "\n",
    "\n",
    "for i in range(List_length):\n",
    "\tfor j in combined[i]:\n",
    "\t\tfile3.write(j + \"\\t\")\n",
    "\tfile3.write(\"\\n\")\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Ground Truth According to Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "\n",
    "file2 = open(\"data/communityalldblp.txt\", \"r\")\n",
    "file3 = open(\"data/SortedGroundTruth.txt\", \"w\")\n",
    "\n",
    "i=0\n",
    "nodesArr = []\n",
    "commArr = []\n",
    "combined = []\n",
    "\n",
    "for items in file2:\n",
    "\titems = items.strip()\n",
    "\titems = items.split(\"\\t\")\n",
    "\tnodes = items[0].strip()\n",
    "\tnodesArr.append(nodes) \n",
    "\tcommunity1 = items[1].strip()\n",
    "\tcommArr.append(community1)\n",
    "\n",
    "List_length = len(nodesArr)\n",
    "\t\n",
    "for i in range(List_length):\n",
    "\tcombined.append([nodesArr[i], commArr[i]])\n",
    "\t#file3.write(nodesArr[i] + \"\\t\" + commArr[i] + \"\\n\")\n",
    "\n",
    "#combined = sorted(combined, key=lambda x: x[0].lower())\n",
    "combined = sorted(combined, key=lambda x: int(x[0]))\n",
    "\n",
    "#print (combined[0])\n",
    "\n",
    "\n",
    "for i in range(List_length):\n",
    "\tfor j in combined[i]:\n",
    "\t\tfile3.write(j + \"\\t\")\n",
    "\tfile3.write(\"\\n\")\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                                Removing Overlapping Communities from Ground Truth \n",
    "The code below removes the overlapping communities i.e one node belongs to multiple communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"data/SortedGroundTruth.txt\", \"r\")\n",
    "file2 = open(\"data/RemovedFile.txt\", \"w\")\n",
    "\n",
    "previousNode = 0\n",
    "\n",
    "for lines in file1:\n",
    "    currLine = lines.strip()\n",
    "    currLine = currLine.split(\"\\t\")\n",
    "    node = currLine[0].strip()\n",
    "    community = currLine[1].strip()\n",
    "\n",
    "    if(previousNode != node):\n",
    "        file2.write(lines)\n",
    "        previousNode = node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Ground Truth According to Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "\n",
    "file2 = open(\"data/communityalldblp.txt\", \"r\")\n",
    "file3 = open(\"data/SortedCommGroundTruth.txt\", \"w\")\n",
    "\n",
    "i=0\n",
    "nodesArr = []\n",
    "commArr = []\n",
    "combined = []\n",
    "\n",
    "for items in file2:\n",
    "\titems = items.strip()\n",
    "\titems = items.split(\"\\t\")\n",
    "\tnodes = items[0].strip()\n",
    "\tnodesArr.append(nodes) \n",
    "\tcommunity1 = items[1].strip()\n",
    "\tcommArr.append(community1)\n",
    "\n",
    "List_length = len(nodesArr)\n",
    "\t\n",
    "for i in range(List_length):\n",
    "\tcombined.append([nodesArr[i], commArr[i]])\n",
    "\t#file3.write(nodesArr[i] + \"\\t\" + commArr[i] + \"\\n\")\n",
    "\n",
    "#combined = sorted(combined, key=lambda x: x[0].lower())\n",
    "combined = sorted(combined, key=lambda x: int(x[1]))\n",
    "\n",
    "#print (combined[0])\n",
    "\n",
    "\n",
    "for i in range(List_length):\n",
    "\tfor j in combined[i]:\n",
    "\t\tfile3.write(j + \"\\t\")\n",
    "\tfile3.write(\"\\n\")\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                                     Ground Truth verification by using Rand Index\n",
    "We have calculated RandIndex of three different methods as the size of ground truth and the communities that were formed were not same.\n",
    "we applied three different methods to make them both equal.\n",
    "\n",
    "    1. Add nodes that were missing from the ground truth and assigned them separate communities.\n",
    "    2. Remove nodes from dblp communities that were missing from the ground truth.\n",
    "    3. Remove nodes from the original dblp dataset and then apply community detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ee606a0c1604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiggerArr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmallArr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbiggerArr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mfile3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiggerArr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Find Missing nodes from Ground Truth Communities\n",
    "\n",
    "\n",
    "smaller = open(\"data/RemovedFile.txt\", \"r\")\n",
    "bigger = open(\"data/SortedDBLPCommunities.txt\", \"r\")\n",
    "file3 = open(\"data/MissingNodes.txt\", \"w\")\n",
    "\n",
    "smallArr = []\n",
    "biggerArr = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for line1 in smaller:\n",
    "    line1 = line1.strip()\n",
    "    line1 = line1.split(\"\\t\")\n",
    "    node = line1[0].strip()\n",
    "    smallArr.append(node)\n",
    "    i = i + 1\n",
    "\n",
    "i = 0\n",
    "\n",
    "for line2 in bigger:\n",
    "    line2 = line2.strip()\n",
    "    line2 = line2.split(\"\\t\")\n",
    "    node1 = line2[0].strip()\n",
    "    biggerArr.append(node1)\n",
    "    i = i + 1\n",
    "\n",
    "#print (len(smallArr))\n",
    "#print (len(biggerArr))\n",
    "\n",
    "k = 0\n",
    "for j in range(len(biggerArr)):\n",
    "    if(smallArr[k] != biggerArr[j]):\n",
    "        file3.write(biggerArr[j]+\"\\n\")\n",
    "    else:\n",
    "        k = k + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Add nodes that were missing from the ground truth and assigned them separatecommunities.\n",
    "\n",
    "\n",
    "file1 = open(\"data/SortedCommGroundTruth.txt\", \"a\")\n",
    "missing = open(\"data/MissingNodes.txt\", \"r\")\n",
    "    \n",
    "community = 13477\n",
    "\n",
    "for lines in missing:\n",
    "    lines = lines.strip()\n",
    "    file1.write(lines + \"\\t\" + str(community) + \"\\n\")\n",
    "    community = community + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Remove nodes from dblp communities that were missing from the ground truth.\n",
    "\n",
    "file1 = open(\"SortedDBLPCommunities.txt\", \"r\")\n",
    "missing = open(\"MissingNodes.txt\", \"r\")\n",
    "file2 = open(\"SortedDBLPCommunitiesNew.txt\", \"a\")\n",
    "missingArr = []\n",
    "flag = 0\n",
    "for item1 in missing:\n",
    "    item1 = item1.strip()\n",
    "    missingArr.append(item1)\n",
    "for lines in file1:\n",
    "    currLine = lines.strip()\n",
    "    currLine = currLine.split(\"\\t\")\n",
    "    node = currLine[0].strip()\n",
    "\n",
    "    for i in range(len(missingArr)):\n",
    "        if(node == missingArr[i]):\n",
    "            flag = 1\n",
    "    if (flag == 0):\n",
    "       file2.write(lines)\n",
    "    flag = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Remove nodes from the original dblp dataset and then apply community detection.\n",
    "\n",
    "file1 = open(\"com-dblp.ungraph.txt\", \"r\")\n",
    "missing = open(\"MissingNodes.txt\", \"r\")\n",
    "file2 = open(\"removeNodesODS.txt\", \"a\")\n",
    "missingArr = []\n",
    "flag = 0\n",
    "for item1 in missing:\n",
    "    item1 = item1.strip()\n",
    "    missingArr.append(item1)\n",
    "for lines in file1:\n",
    "    currLine = lines.strip()\n",
    "    currLine = currLine.split(\"\\t\")\n",
    "    node1 = currLine[0].strip()\n",
    "    node2 = currLine[1].strip()\n",
    "\n",
    "    for i in range(len(missingArr)):\n",
    "        if((node1 == missingArr[i]) or (node2 == missingArr[i])):\n",
    "            flag = 1\n",
    "    if (flag == 0):\n",
    "       file2.write(lines)\n",
    "    flag = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
